{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the movie reviews data provided (and already tokenized) for you, you will make a new Python 3 sentiment_classifier.py file where you will implement Naive Bayes and logistic regression for predicting the sentiment of movie reviews in the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sents = []\n",
    "train_labels = []\n",
    "val_sents = []\n",
    "val_labels = []\n",
    "\n",
    "with open('train.txt') as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.strip().split()\n",
    "        train_sents.append(line[1:])\n",
    "        train_labels.append(int(line[0]))\n",
    "\n",
    "with open('val.txt') as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.strip().split()\n",
    "        val_sents.append(line[1:])\n",
    "        val_labels.append(int(line[0]))\n",
    "        \n",
    "train_labels = np.array(train_labels)\n",
    "val_labels = np.array(val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, as a simple baseline, implement a classifier that always predicts label 1 (i.e. positive), and evaluate it on both the training and validation datasets. You should see an accuracy of roughly 50%, which is just as bad as a random guess!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones_pred_train = np.ones(np.shape(train_labels))\n",
    "ones_pred_val = np.ones(np.shape(val_labels))\n",
    "\n",
    "train_scores = np.where(ones_pred_train == train_labels, 1.0, 0.0)\n",
    "train_acc = np.mean(train_scores)\n",
    "\n",
    "val_scores = np.where(ones_pred_val == val_labels, 1.0, 0.0)\n",
    "val_acc = np.mean(val_scores)\n",
    "\n",
    "print('Random Train Accuracy:', train_acc)\n",
    "print('Random Validation Accuracy:', val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement a multinomial Naive Bayes classifier with the scikit-learn toolkit that uses unigram feaures. \n",
    "### What are your training and validation accuracies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [' '.join(ele) for ele in train_sents]\n",
    "val = [' '.join(ele) for ele in val_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "train_data = cv.fit_transform(train)\n",
    "val_data = cv.transform(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Training Accuract: 0.9414739884393064\n"
     ]
    }
   ],
   "source": [
    "MNB = MultinomialNB()\n",
    "MNB.fit(train_data, train_labels)\n",
    "MNB_train_acc = MNB.score(train_data, train_labels)\n",
    "print('Naive Bayes Training Accuracy:', MNB_train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Validation Accuracy: 0.8038990825688074\n"
     ]
    }
   ],
   "source": [
    "MNB_preds = MNB.predict(val_data)\n",
    "score = np.where(MNB_preds == val_labels, 1.0, 0.0)\n",
    "mean = np.mean(score)\n",
    "print('Naive Bayes Validation Accuracy:', mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now build a logistic regression classifier, again using the scikit-learn toolkit with unigram features.\n",
    "### How does it compare to Naive Bayes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Train Accuracy: 0.9804913294797688\n"
     ]
    }
   ],
   "source": [
    "LR = LogisticRegression(max_iter=1500)\n",
    "LR.fit(train_data, train_labels)\n",
    "LR_train_acc = LR.score(train_data, train_labels)\n",
    "print('Logistic Regression Train Accuracy:', LR_train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ligistic Regression Validation Accuracy: 0.7878440366972477\n"
     ]
    }
   ],
   "source": [
    "LR_preds = LR.predict(val_data)\n",
    "score = np.where(LR_preds == val_labels, 1.0, 0.0)\n",
    "mean = np.mean(score)\n",
    "print('Ligistic Regression Validation Accuracy:', mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, add bigram features to the logistic regression. \n",
    "### Do the new accuracies match your intuition?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2 = CountVectorizer(analyzer='word', ngram_range=(2, 2))\n",
    "train_data = cv2.fit_transform(train)\n",
    "val_data = cv2.transform(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Train Accuracy: 0.9975433526011561\n"
     ]
    }
   ],
   "source": [
    "LR2 = LogisticRegression(max_iter=1500)\n",
    "LR2.fit(train_data, train_labels)\n",
    "LR2_train_acc = LR2.score(train_data, train_labels)\n",
    "print('Logistic Regression Train Accuracy:', LR2_train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Validation Accuracy: 0.7155963302752294\n"
     ]
    }
   ],
   "source": [
    "LR2_preds = LR2.predict(val_data)\n",
    "score = np.where(LR2_preds == val_labels, 1.0, 0.0)\n",
    "mean = np.mean(score)\n",
    "print('Logistic Regression Validation Accuracy:', mean)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
