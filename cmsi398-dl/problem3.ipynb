{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from random import randint\n",
    "import time\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n",
      "tensor([[2, 1, 0],\n",
      "        [5, 4, 3],\n",
      "        [8, 7, 6]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(9).view(3,3)\n",
    "print(x)\n",
    "x = torch.flip(x,[1])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50000, 3, 32, 32])\n",
      "torch.Size([10000, 3, 32, 32])\n",
      "torch.Size([50000, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "train_data=torch.load('../../data/cifar/train_data.pt')\n",
    "train_label=torch.load('../../data/cifar/train_label.pt')\n",
    "test_data=torch.load('../../data/cifar/test_data.pt')\n",
    "test_label=torch.load('../../data/cifar/test_label.pt')\n",
    "print(train_data.size())\n",
    "print(test_data.size())\n",
    "\n",
    "train_data_flip = torch.flip(train_data,[3])\n",
    "train_label_flip = train_label\n",
    "print(train_data_flip.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 50000, 3, 32, 32])\n",
      "torch.Size([100000, 3, 32, 32])\n",
      "torch.Size([100000])\n"
     ]
    }
   ],
   "source": [
    "train_data = torch.stack([train_data, train_data_flip],0)\n",
    "train_label = torch.stack([train_label, train_label_flip],0)\n",
    "print(train_data.size())\n",
    "\n",
    "train_data = train_data.view(100000,3,32,32)\n",
    "train_label = train_label.view(100000)\n",
    "print(train_data.size())\n",
    "print(train_label.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.2314, 0.1686, 0.1961,  ..., 0.6196, 0.5961, 0.5804],\n",
      "         [0.0627, 0.0000, 0.0706,  ..., 0.4824, 0.4667, 0.4784],\n",
      "         [0.0980, 0.0627, 0.1922,  ..., 0.4627, 0.4706, 0.4275],\n",
      "         ...,\n",
      "         [0.8157, 0.7882, 0.7765,  ..., 0.6275, 0.2196, 0.2078],\n",
      "         [0.7059, 0.6784, 0.7294,  ..., 0.7216, 0.3804, 0.3255],\n",
      "         [0.6941, 0.6588, 0.7020,  ..., 0.8471, 0.5922, 0.4824]],\n",
      "\n",
      "        [[0.2431, 0.1804, 0.1882,  ..., 0.5176, 0.4902, 0.4863],\n",
      "         [0.0784, 0.0000, 0.0314,  ..., 0.3451, 0.3255, 0.3412],\n",
      "         [0.0941, 0.0275, 0.1059,  ..., 0.3294, 0.3294, 0.2863],\n",
      "         ...,\n",
      "         [0.6667, 0.6000, 0.6314,  ..., 0.5216, 0.1216, 0.1333],\n",
      "         [0.5451, 0.4824, 0.5647,  ..., 0.5804, 0.2431, 0.2078],\n",
      "         [0.5647, 0.5059, 0.5569,  ..., 0.7216, 0.4627, 0.3608]],\n",
      "\n",
      "        [[0.2471, 0.1765, 0.1686,  ..., 0.4235, 0.4000, 0.4039],\n",
      "         [0.0784, 0.0000, 0.0000,  ..., 0.2157, 0.1961, 0.2235],\n",
      "         [0.0824, 0.0000, 0.0314,  ..., 0.1961, 0.1961, 0.1647],\n",
      "         ...,\n",
      "         [0.3765, 0.1333, 0.1020,  ..., 0.2745, 0.0275, 0.0784],\n",
      "         [0.3765, 0.1647, 0.1176,  ..., 0.3686, 0.1333, 0.1333],\n",
      "         [0.4549, 0.3686, 0.3412,  ..., 0.5490, 0.3294, 0.2824]]])\n",
      "tensor([[[0.5804, 0.5961, 0.6196,  ..., 0.1961, 0.1686, 0.2314],\n",
      "         [0.4784, 0.4667, 0.4824,  ..., 0.0706, 0.0000, 0.0627],\n",
      "         [0.4275, 0.4706, 0.4627,  ..., 0.1922, 0.0627, 0.0980],\n",
      "         ...,\n",
      "         [0.2078, 0.2196, 0.6275,  ..., 0.7765, 0.7882, 0.8157],\n",
      "         [0.3255, 0.3804, 0.7216,  ..., 0.7294, 0.6784, 0.7059],\n",
      "         [0.4824, 0.5922, 0.8471,  ..., 0.7020, 0.6588, 0.6941]],\n",
      "\n",
      "        [[0.4863, 0.4902, 0.5176,  ..., 0.1882, 0.1804, 0.2431],\n",
      "         [0.3412, 0.3255, 0.3451,  ..., 0.0314, 0.0000, 0.0784],\n",
      "         [0.2863, 0.3294, 0.3294,  ..., 0.1059, 0.0275, 0.0941],\n",
      "         ...,\n",
      "         [0.1333, 0.1216, 0.5216,  ..., 0.6314, 0.6000, 0.6667],\n",
      "         [0.2078, 0.2431, 0.5804,  ..., 0.5647, 0.4824, 0.5451],\n",
      "         [0.3608, 0.4627, 0.7216,  ..., 0.5569, 0.5059, 0.5647]],\n",
      "\n",
      "        [[0.4039, 0.4000, 0.4235,  ..., 0.1686, 0.1765, 0.2471],\n",
      "         [0.2235, 0.1961, 0.2157,  ..., 0.0000, 0.0000, 0.0784],\n",
      "         [0.1647, 0.1961, 0.1961,  ..., 0.0314, 0.0000, 0.0824],\n",
      "         ...,\n",
      "         [0.0784, 0.0275, 0.2745,  ..., 0.1020, 0.1333, 0.3765],\n",
      "         [0.1333, 0.1333, 0.3686,  ..., 0.1176, 0.1647, 0.3765],\n",
      "         [0.2824, 0.3294, 0.5490,  ..., 0.3412, 0.3686, 0.4549]]])\n",
      "tensor(6)\n",
      "tensor(6)\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])\n",
    "print(train_data[50000])\n",
    "print(train_label[0])\n",
    "print(train_label[50000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class convnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # block 1 - 3x32x32 to __x16x16\n",
    "        self.conv1a = nn.Conv2d(3, 64, kernel_size = 3, padding = 1)\n",
    "        self.conv1b = nn.Conv2d(64, 64, kernel_size = 3, padding = 1)\n",
    "        self.conv1c = nn.Conv2d(64, 64, kernel_size = 3, padding = 1)\n",
    "        self.conv1d = nn.Conv2d(64, 64, kernel_size = 3, padding = 1)\n",
    "        self.conv1e = nn.Conv2d(64, 64, kernel_size = 3, padding = 1)\n",
    "        self.conv1f = nn.Conv2d(64, 64, kernel_size = 3, padding = 1)\n",
    "        self.conv1g = nn.Conv2d(64, 64, kernel_size = 3, padding = 1)\n",
    "        self.pool1 = nn.MaxPool2d(2,2)\n",
    "        \n",
    "        # block 2 - __x16x16 to __x8x8\n",
    "        self.conv2a = nn.Conv2d(64, 128, kernel_size = 3, padding = 1)\n",
    "        self.conv2b = nn.Conv2d(128, 128, kernel_size = 3, padding = 1)\n",
    "        self.conv2c = nn.Conv2d(128, 128, kernel_size = 3, padding = 1)\n",
    "        self.conv2d = nn.Conv2d(128, 128, kernel_size = 3, padding = 1)\n",
    "        self.conv2e = nn.Conv2d(128, 128, kernel_size = 3, padding = 1)\n",
    "        self.conv2f = nn.Conv2d(128, 128, kernel_size = 3, padding = 1)\n",
    "        self.conv2g = nn.Conv2d(128, 128, kernel_size = 3, padding = 1)\n",
    "        self.pool2 = nn.MaxPool2d(2,2)\n",
    "        \n",
    "        # block 3 - __x8x8 to __x2x2\n",
    "        self.conv3a = nn.Conv2d(128, 256, kernel_size = 3, padding = 1)\n",
    "        self.conv3b = nn.Conv2d(256, 256, kernel_size = 3, padding = 1)\n",
    "        self.conv3c = nn.Conv2d(256, 256, kernel_size = 3, padding = 1)\n",
    "        self.conv3d = nn.Conv2d(256, 256, kernel_size = 3, padding = 1)\n",
    "        self.conv3e = nn.Conv2d(256, 256, kernel_size = 3, padding = 1)\n",
    "        self.conv3f = nn.Conv2d(256, 256, kernel_size = 3, padding = 1)\n",
    "        self.conv3g = nn.Conv2d(256, 256, kernel_size = 3, padding = 1)\n",
    "        self.pool3 = nn.MaxPool2d(2,2)\n",
    "        \n",
    "        # block 4 - __x4x4 to __x2x2\n",
    "        self.conv4a = nn.Conv2d(256, 512, kernel_size = 3, padding = 1)\n",
    "        self.pool4 = nn.MaxPool2d(2,2)\n",
    "        \n",
    "        # linear layers - \n",
    "        self.linear1 = nn.Linear(2048, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # block 1\n",
    "        a1 = self.conv1a(x)\n",
    "        a1 = F.relu(a1)\n",
    "        b1 = self.conv1b(a1)\n",
    "        b1 = F.relu(b1)\n",
    "        c1 = self.conv1c(b1) \n",
    "        c1 = F.relu(c1) + a1\n",
    "        d1 = self.conv1d(c1)\n",
    "        d1 = F.relu(d1)\n",
    "        e1 = self.conv1e(d1) \n",
    "        e1 = F.relu(e1) + c1\n",
    "        f1 = self.conv1f(e1)\n",
    "        f1 = F.relu(f1)\n",
    "        g1 = self.conv1g(f1) \n",
    "        g1 = F.relu(g1) + e1\n",
    "        p1 = self.pool1(g1)\n",
    "        \n",
    "        # block 2\n",
    "        a2 = self.conv2a(p1)\n",
    "        a2 = F.relu(a2)\n",
    "        b2 = self.conv2b(a2)\n",
    "        b2 = F.relu(b2)\n",
    "        c2 = self.conv2c(b2) \n",
    "        c2 = F.relu(c2) + a2\n",
    "        d2 = self.conv2d(c2)\n",
    "        d2 = F.relu(d2)\n",
    "        e2 = self.conv2e(d2) \n",
    "        e2 = F.relu(e2) + c2\n",
    "        f2 = self.conv2f(e2)\n",
    "        f2 = F.relu(f2)\n",
    "        g2 = self.conv2g(f2) \n",
    "        g2 = F.relu(g2) + e2\n",
    "        p2 = self.pool2(g2)\n",
    "        \n",
    "        # block 3\n",
    "        a3 = self.conv3a(p2)\n",
    "        a3 = F.relu(a3)\n",
    "        b3 = self.conv3b(a3)\n",
    "        b3 = F.relu(b3)\n",
    "        c3 = self.conv3c(b3) \n",
    "        c3 = F.relu(c3) + a3\n",
    "        d3 = self.conv3d(c3)\n",
    "        d3 = F.relu(d3)\n",
    "        e3 = self.conv3e(d3) \n",
    "        e3 = F.relu(e3) + c3\n",
    "        f3 = self.conv3f(e3)\n",
    "        f3 = F.relu(f3)\n",
    "        g3 = self.conv3g(f3) \n",
    "        g3 = F.relu(g3) + e3\n",
    "        p3 = self.pool3(g3)\n",
    "        \n",
    "        # block 4\n",
    "        a4 = self.conv4a(p3)\n",
    "        a4 = F.relu(a4)\n",
    "        p4 = self.pool4(a4)\n",
    "        \n",
    "        # linear layers\n",
    "        p4 = p4.view(-1,2048)\n",
    "        scores = self.linear1(p4)\n",
    "        \n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6219018 (6.22 million) parameters in this neural network\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "net = convnet()\n",
    "utils.display_num_param(net)\n",
    "net = net.to(device)\n",
    "mean= train_data.mean()\n",
    "std= train_data.std()\n",
    "mean= mean.to(device)\n",
    "std= std.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "my_lr = 0.25\n",
    "\n",
    "bs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_on_test_set():\n",
    "\n",
    "    running_error=0\n",
    "    num_batches=0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        for i in range(0,10000,bs):\n",
    "\n",
    "            minibatch_data =  test_data[i:i+bs]\n",
    "            minibatch_label= test_label[i:i+bs]\n",
    "            \n",
    "            minibatch_data = minibatch_data.to(device)\n",
    "            minibatch_label = minibatch_label.to(device)\n",
    "\n",
    "            inputs = (minibatch_data - mean)/std\n",
    "\n",
    "            scores=net( inputs ) \n",
    "\n",
    "            error = utils.get_error(scores , minibatch_label)\n",
    "\n",
    "            running_error += error.item()\n",
    "\n",
    "            num_batches+=1\n",
    "\n",
    "\n",
    "    total_error = running_error/num_batches\n",
    "    print( 'test error  = ', total_error*100,'percent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "epoch= 0 \t time= 91.86796355247498 \t loss= 1.6721508145332336 \t error= 61.28400065898896 percent\n",
      "test error  =  43.980000734329224 percent\n",
      " \n",
      "epoch= 1 \t time= 187.66155314445496 \t loss= 1.0292969111204147 \t error= 36.37100149393081 percent\n",
      "test error  =  32.44000160694122 percent\n",
      " \n",
      "epoch= 2 \t time= 283.37278842926025 \t loss= 0.7318337965011597 \t error= 25.433001852035524 percent\n",
      "test error  =  26.860002279281613 percent\n",
      " \n",
      "epoch= 3 \t time= 379.1510376930237 \t loss= 0.5592886995077133 \t error= 19.353001940250397 percent\n",
      "test error  =  24.250001668930054 percent\n",
      " \n",
      "epoch= 4 \t time= 475.0072100162506 \t loss= 0.32506784704327585 \t error= 11.280001831054689 percent\n",
      "test error  =  18.840001463890076 percent\n",
      " \n",
      "epoch= 5 \t time= 570.9699511528015 \t loss= 0.23536198130249977 \t error= 8.150002181529999 percent\n",
      "test error  =  20.39000165462494 percent\n",
      " \n",
      "epoch= 6 \t time= 666.9752659797668 \t loss= 0.16077808641642333 \t error= 5.479001724720002 percent\n",
      "test error  =  20.32000243663788 percent\n",
      " \n",
      "epoch= 7 \t time= 762.9585385322571 \t loss= 0.10385999881476164 \t error= 3.525002729892731 percent\n",
      "test error  =  19.01000201702118 percent\n",
      " \n",
      "epoch= 8 \t time= 858.983824968338 \t loss= 0.024637463787570597 \t error= 0.5910013794898986 percent\n",
      "test error  =  18.110001802444458 percent\n",
      " \n",
      "epoch= 9 \t time= 955.0231213569641 \t loss= 0.00497045924840495 \t error= 0.028999972343444824 percent\n",
      "test error  =  17.500001907348633 percent\n",
      " \n",
      "epoch= 10 \t time= 1051.1317918300629 \t loss= 0.0017485884982743301 \t error= 0.0 percent\n",
      "test error  =  17.42000186443329 percent\n",
      " \n",
      "epoch= 11 \t time= 1147.2408292293549 \t loss= 0.0012602599596139043 \t error= 0.0 percent\n",
      "test error  =  17.300001859664917 percent\n",
      " \n",
      "epoch= 12 \t time= 1243.2974219322205 \t loss= 0.0010265458817593754 \t error= 0.0 percent\n",
      "test error  =  17.360001921653748 percent\n",
      " \n",
      "epoch= 13 \t time= 1339.335357427597 \t loss= 0.0009337432764004916 \t error= 0.0 percent\n",
      "test error  =  17.440001964569092 percent\n",
      " \n",
      "epoch= 14 \t time= 1435.3875110149384 \t loss= 0.0008574560033739545 \t error= 0.0 percent\n",
      "test error  =  17.390002012252808 percent\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "for epoch in range(15):\n",
    "    \n",
    "    if epoch == 4 or epoch == 8 or epoch == 10 or epoch == 12:\n",
    "        my_lr = my_lr * 0.5\n",
    "        \n",
    "    optimizer=torch.optim.SGD( net.parameters() , lr=my_lr )\n",
    "    \n",
    "    running_loss=0\n",
    "    running_error=0\n",
    "    num_batches=0\n",
    "    \n",
    "    shuffled_indices=torch.randperm(100000)\n",
    " \n",
    "    for count in range(0,100000,bs):\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        indices=shuffled_indices[count:count+bs]\n",
    "        minibatch_data =  train_data[indices]\n",
    "        minibatch_label= train_label[indices]\n",
    "        \n",
    "        minibatch_data = minibatch_data.to(device)\n",
    "        minibatch_label = minibatch_label.to(device)\n",
    "\n",
    "        inputs = minibatch_data\n",
    "        inputs = inputs - mean\n",
    "        inputs = inputs / std\n",
    "\n",
    "        inputs.requires_grad_(True)\n",
    "\n",
    "        scores=net( inputs ) \n",
    "\n",
    "        loss =  criterion(scores , minibatch_label) \n",
    "        \n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        # compute some stats\n",
    "        \n",
    "        num_batches+=1\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "\n",
    "            error = utils.get_error(scores , minibatch_label)\n",
    "            running_error += error.item() \n",
    "    \n",
    "    \n",
    "    # once the epoch is finished we divide the \"running quantities\"\n",
    "    # by the number of batches\n",
    "    \n",
    "    total_loss = running_loss/num_batches\n",
    "    total_error = running_error/num_batches\n",
    "    elapsed_time = time.time() - start\n",
    "    \n",
    "    # every 1 epoch we display the stats \n",
    "    # and compute the error rate on the test set  \n",
    "    \n",
    "    if epoch % 1 == 0: \n",
    "    \n",
    "        print(' ')\n",
    "        \n",
    "        print('epoch=',epoch, '\\t time=', elapsed_time,\n",
    "              '\\t loss=', total_loss , '\\t error=', total_error*100 ,'percent')\n",
    "        \n",
    "        eval_on_test_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
