{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.datasets as skdata\n",
    "from sklearn.linear_model import Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nName: Escalante, Tomas\\n\\nCollaborators: N/A\\n\\nCollaboration details: N/A\\n\\nSummary:\\nReport your scores here. For example,\\n\\nResults using scikit-learn Perceptron model\\nTraining set mean accuracy: 0.8289\\nValidation set mean accuracy: 0.7778\\nTesting set mean accuracy: 0.8200\\nResults using our Perceptron model trained with 10 steps\\nTraining set mean accuracy: 0.5351\\nValidation set mean accuracy: 0.5714\\nResults using our Perceptron model trained with 20 steps\\nTraining set mean accuracy: 0.7500\\nValidation set mean accuracy: 0.7619\\nResults using our Perceptron model trained with 60 steps\\nTraining set mean accuracy: 0.8355\\nValidation set mean accuracy: 0.8889\\nUsing best model trained with 60 steps\\nTesting set mean accuracy: 0.8400\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Name: Escalante, Tomas\n",
    "\n",
    "Collaborators: N/A\n",
    "\n",
    "Collaboration details: N/A\n",
    "\n",
    "Summary:\n",
    "Report your scores here. For example,\n",
    "\n",
    "Results using scikit-learn Perceptron model\n",
    "Training set mean accuracy: 0.8289\n",
    "Validation set mean accuracy: 0.7778\n",
    "Testing set mean accuracy: 0.8200\n",
    "Results using our Perceptron model trained with 10 steps\n",
    "Training set mean accuracy: 0.5351\n",
    "Validation set mean accuracy: 0.5714\n",
    "Results using our Perceptron model trained with 20 steps\n",
    "Training set mean accuracy: 0.7500\n",
    "Validation set mean accuracy: 0.7619\n",
    "Results using our Perceptron model trained with 60 steps\n",
    "Training set mean accuracy: 0.8355\n",
    "Validation set mean accuracy: 0.8889\n",
    "Using best model trained with 60 steps\n",
    "Testing set mean accuracy: 0.8400\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Implementation of Perceptron for binary classification\n",
    "'''\n",
    "class PerceptronBinary(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        # Define private variables\n",
    "        self.__weights = None\n",
    "\n",
    "    def __update(self, x, y):\n",
    "        '''\n",
    "        Update the weight vector during each training iteration\n",
    "\n",
    "        Args:\n",
    "            x : numpy\n",
    "                d x N feature vector\n",
    "            y : numpy\n",
    "                1 x N ground-truth label\n",
    "        '''\n",
    "        # TODO: Implement the member update function\n",
    "        \n",
    "        # Augment the feature vector x (d, N) with threshold (1, N)\n",
    "        threshold = 0.5 * np.ones([1, x.shape[1]]) # (1, N)\n",
    "        x = np.concatenate([threshold, x], axis = 0) # (d+1, N)\n",
    "        \n",
    "        # Walk through every example and check if they are incorrect\n",
    "        for i in range(x.shape[1]):\n",
    "            # x is (d+1, N), so the shape is (d+1), weights is (d+1, 1)\n",
    "            x_i = np.expand_dims(x[:, i], axis = -1) # has shape of (d+1, 1)\n",
    "            # we can also use np.reshape(x[:, n], (-1,1))\n",
    "            \n",
    "            # Predict the label for x_i\n",
    "            prediction = np.sign(np.matmul(self.__weights.T, x_i))\n",
    "            \n",
    "            # Check if prediction is equal or not equal to ground truth y\n",
    "            if prediction != y[i]:\n",
    "                # w^(t+1) = w^(t) + (y^i * x^i)\n",
    "                self.__weights = self.__weights + (y[i] * x_i)\n",
    "                \n",
    "            \n",
    "\n",
    "    def fit(self, x, y, T, tol):\n",
    "        '''\n",
    "        Fits the model to x and y by updating the weight vector\n",
    "        based on mis-classified examples for t iterations until convergence\n",
    "\n",
    "        Args:\n",
    "            x : numpy\n",
    "                d x N feature vector\n",
    "            y : numpy\n",
    "                1 x N ground-truth label\n",
    "            t : int\n",
    "                number of iterations to optimize perceptron\n",
    "            tol : float\n",
    "                change of loss tolerance, if greater than loss + tolerance, then stop\n",
    "        '''\n",
    "        # TODO: Implement the fit function\n",
    "        \n",
    "        # initialize the weights\n",
    "        self.__weights = np.zeros([x.shape[0] + 1, 1]) # (d+1, 1)\n",
    "        self.__weights[0, 0] = -1.0\n",
    "        \n",
    "        \n",
    "        # Initialize previous loss and weights\n",
    "        prev_loss = 2.0\n",
    "        prev_weights = np.copy(self.__weights)\n",
    "        \n",
    "        for t in range(T):\n",
    "            # Compute the loss\n",
    "            predictions = self.predict(x)\n",
    "            \n",
    "            # l = 1/N \\sum_i^N I(h(x^i) != y^i)\n",
    "            loss = np.mean(np.where(predictions != y, 1.0, 0.0))\n",
    "            print('t={} loss={}'.format(t+1, loss))\n",
    "            \n",
    "            # Stopping conditions\n",
    "            if loss == 0.0:\n",
    "                break\n",
    "            elif loss > prev_loss + tol and t > 2:\n",
    "                self.__weights = prev_weights\n",
    "                break\n",
    "            \n",
    "            # Update previous loss and precious weights\n",
    "            prev_loss = loss\n",
    "            prev_weights = np.copy(self.__weights)\n",
    "            \n",
    "            # Updates our weight vector based on what we got wrong\n",
    "            self.__update(x, y)\n",
    "\n",
    "    def predict(self, x):\n",
    "        '''\n",
    "        Predicts the label for each feature vector x\n",
    "\n",
    "        Args:\n",
    "            x : numpy\n",
    "                d x N feature vector\n",
    "\n",
    "        Returns:\n",
    "            numpy : d x 1 label vector\n",
    "        '''\n",
    "        # TODO: Implement the predict function\n",
    "        \n",
    "        # [w0, w1, w2, w3, ..., wd] (d+1, N)\n",
    "        # [..., x1, x2, x3, ..., xd] (d, N)\n",
    "        # What is the shape of threshold? (1, N)\n",
    "        \n",
    "        threshold = 0.5 * np.ones([1, x.shape[1]]) # (1, N)\n",
    "        \n",
    "        # Augment the the features x with the threshold\n",
    "        x = np.concatenate([threshold, x], axis = 0) # (d+1, N)\n",
    "        \n",
    "        # Predict using w^Tx: \n",
    "        predictions = np.matmul(self.__weights.T, x) # (1, N)\n",
    "        \n",
    "        # What we care about is the sign of our predictions +/-\n",
    "        # h(x) = sign(w^Tx)\n",
    "        return np.sign(predictions)\n",
    "\n",
    "    def score(self, x, y):\n",
    "        '''\n",
    "        Predicts labels based on feature vector x and computes the mean accuracy\n",
    "        of the predictions\n",
    "\n",
    "        Args:\n",
    "            x : numpy\n",
    "                d x N feature vector\n",
    "            y : numpy\n",
    "                1 x N ground-truth label\n",
    "\n",
    "        Returns:\n",
    "            float : mean accuracy\n",
    "        '''\n",
    "        # TODO: Implement the score function\n",
    "        \n",
    "        predictions = self.predict(x) # (1, N) of {-1, +1}\n",
    "        \n",
    "        # Comparing if predictions and y are the same\n",
    "        scores = np.where(predictions == y, 1.0, 0.0)\n",
    "        \n",
    "        # Return the mean accuracy\n",
    "        return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results using scikit-learn Perceptron model\n",
      "Training set mean accuracy: 0.8289\n",
      "Validation set mean accuracy: 0.7778\n",
      "Testing set mean accuracy: 0.8200\n",
      "Results using our Perceptron model trained with 10 steps\n",
      "t=1 loss=0.631578947368421\n",
      "t=2 loss=0.19517543859649122\n",
      "t=3 loss=0.3026315789473684\n",
      "t=4 loss=0.20394736842105263\n",
      "t=5 loss=0.19956140350877194\n",
      "t=6 loss=0.19078947368421054\n",
      "t=7 loss=0.31140350877192985\n",
      "t=8 loss=0.3201754385964912\n",
      "t=9 loss=0.19736842105263158\n",
      "t=10 loss=0.5109649122807017\n",
      "Training set mean accuracy: 0.5351\n",
      "Validation set mean accuracy: 0.5714\n",
      "Results using our Perceptron model trained with 20 steps\n",
      "t=1 loss=0.631578947368421\n",
      "t=2 loss=0.19517543859649122\n",
      "t=3 loss=0.3026315789473684\n",
      "t=4 loss=0.20394736842105263\n",
      "t=5 loss=0.19956140350877194\n",
      "t=6 loss=0.19078947368421054\n",
      "t=7 loss=0.31140350877192985\n",
      "t=8 loss=0.3201754385964912\n",
      "t=9 loss=0.19736842105263158\n",
      "t=10 loss=0.5109649122807017\n",
      "t=11 loss=0.4649122807017544\n",
      "t=12 loss=0.42543859649122806\n",
      "t=13 loss=0.19298245614035087\n",
      "t=14 loss=0.28728070175438597\n",
      "t=15 loss=0.2675438596491228\n",
      "t=16 loss=0.15789473684210525\n",
      "t=17 loss=0.3574561403508772\n",
      "t=18 loss=0.26535087719298245\n",
      "t=19 loss=0.17763157894736842\n",
      "t=20 loss=0.16447368421052633\n",
      "Training set mean accuracy: 0.7500\n",
      "Validation set mean accuracy: 0.7619\n",
      "Results using our Perceptron model trained with 60 steps\n",
      "t=1 loss=0.631578947368421\n",
      "t=2 loss=0.19517543859649122\n",
      "t=3 loss=0.3026315789473684\n",
      "t=4 loss=0.20394736842105263\n",
      "t=5 loss=0.19956140350877194\n",
      "t=6 loss=0.19078947368421054\n",
      "t=7 loss=0.31140350877192985\n",
      "t=8 loss=0.3201754385964912\n",
      "t=9 loss=0.19736842105263158\n",
      "t=10 loss=0.5109649122807017\n",
      "t=11 loss=0.4649122807017544\n",
      "t=12 loss=0.42543859649122806\n",
      "t=13 loss=0.19298245614035087\n",
      "t=14 loss=0.28728070175438597\n",
      "t=15 loss=0.2675438596491228\n",
      "t=16 loss=0.15789473684210525\n",
      "t=17 loss=0.3574561403508772\n",
      "t=18 loss=0.26535087719298245\n",
      "t=19 loss=0.17763157894736842\n",
      "t=20 loss=0.16447368421052633\n",
      "t=21 loss=0.25\n",
      "t=22 loss=0.13815789473684212\n",
      "t=23 loss=0.1337719298245614\n",
      "t=24 loss=0.29385964912280704\n",
      "t=25 loss=0.23684210526315788\n",
      "t=26 loss=0.16885964912280702\n",
      "t=27 loss=0.17763157894736842\n",
      "t=28 loss=0.13157894736842105\n",
      "t=29 loss=0.17105263157894737\n",
      "t=30 loss=0.2236842105263158\n",
      "t=31 loss=0.4407894736842105\n",
      "t=32 loss=0.14692982456140352\n",
      "t=33 loss=0.14912280701754385\n",
      "t=34 loss=0.14912280701754385\n",
      "t=35 loss=0.18201754385964913\n",
      "t=36 loss=0.17105263157894737\n",
      "t=37 loss=0.14912280701754385\n",
      "t=38 loss=0.3530701754385965\n",
      "t=39 loss=0.4144736842105263\n",
      "t=40 loss=0.3618421052631579\n",
      "t=41 loss=0.4144736842105263\n",
      "t=42 loss=0.4232456140350877\n",
      "t=43 loss=0.37719298245614036\n",
      "t=44 loss=0.28289473684210525\n",
      "t=45 loss=0.3706140350877193\n",
      "t=46 loss=0.2916666666666667\n",
      "t=47 loss=0.37280701754385964\n",
      "t=48 loss=0.3881578947368421\n",
      "t=49 loss=0.3881578947368421\n",
      "t=50 loss=0.3881578947368421\n",
      "t=51 loss=0.38377192982456143\n",
      "t=52 loss=0.3706140350877193\n",
      "t=53 loss=0.39035087719298245\n",
      "t=54 loss=0.38377192982456143\n",
      "t=55 loss=0.37280701754385964\n",
      "t=56 loss=0.4100877192982456\n",
      "t=57 loss=0.38377192982456143\n",
      "t=58 loss=0.35526315789473684\n",
      "t=59 loss=0.1600877192982456\n",
      "t=60 loss=0.3618421052631579\n",
      "Training set mean accuracy: 0.8355\n",
      "Validation set mean accuracy: 0.8889\n",
      "Using best model trained with 60 steps\n",
      "Testing set mean accuracy: 0.8400\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    breast_cancer_data = skdata.load_breast_cancer()\n",
    "    x = breast_cancer_data.data\n",
    "    y = breast_cancer_data.target\n",
    "\n",
    "    # 80 percent train, 10 percent validation, 10 percent test split\n",
    "    train_idx = []\n",
    "    val_idx = []\n",
    "    test_idx = []\n",
    "    for idx in range(x.shape[0]):\n",
    "        if idx and idx % 9 == 0:\n",
    "            val_idx.append(idx)\n",
    "        elif idx and idx % 10 == 0:\n",
    "            test_idx.append(idx)\n",
    "        else:\n",
    "            train_idx.append(idx)\n",
    "\n",
    "    x_train, x_val, x_test = x[train_idx, :], x[val_idx, :], x[test_idx, :]\n",
    "    y_train, y_val, y_test = y[train_idx], y[val_idx], y[test_idx]\n",
    "\n",
    "    '''\n",
    "    Trains and tests Perceptron model from scikit-learn\n",
    "    '''\n",
    "    model = Perceptron(penalty=None, alpha=0.0, tol=1e-3)\n",
    "    # Trains scikit-learn Perceptron model\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    print('Results using scikit-learn Perceptron model')\n",
    "\n",
    "    # Test model on training set\n",
    "    scores_train = model.score(x_train, y_train)\n",
    "    print('Training set mean accuracy: {:.4f}'.format(scores_train))\n",
    "\n",
    "    # Test model on validation set\n",
    "    scores_val = model.score(x_val, y_val)\n",
    "    print('Validation set mean accuracy: {:.4f}'.format(scores_val))\n",
    "\n",
    "    # Test model on testing set\n",
    "    scores_test = model.score(x_test, y_test)\n",
    "    print('Testing set mean accuracy: {:.4f}'.format(scores_test))\n",
    "\n",
    "    '''\n",
    "    Trains and tests our Perceptron model for binary classification\n",
    "    '''\n",
    "    # TODO: obtain dataset in correct shape (d x N)\n",
    "    \n",
    "    x_train = np.transpose(x_train, axes=(1, 0))\n",
    "    x_val = np.transpose(x_val, axes=(1, 0))\n",
    "    x_test = np.transpose(x_test, axes=(1, 0))\n",
    "\n",
    "    # TODO: obtain labels in {+1, -1} format\n",
    "    \n",
    "    y_train = np.where(y_train == 0, -1, 1)\n",
    "    y_val = np.where(y_val == 0, -1, 1)\n",
    "    y_test = np.where(y_test == 0, -1, 1)\n",
    "\n",
    "    # TODO: Initialize model, train model, score model on train, val and test sets\n",
    "    \n",
    "    model = PerceptronBinary()\n",
    "    \n",
    "    # Train 3 PerceptronBinary models using 10, 50, and 60 steps with tolerance of 1\n",
    "    models = []\n",
    "    scores = []\n",
    "    steps = [10, 20, 60]\n",
    "    for T in steps:\n",
    "        # Initialize PerceptronBinary model\n",
    "        model = PerceptronBinary()\n",
    "\n",
    "        print('Results using our Perceptron model trained with {} steps'.format(T))\n",
    "        # Train model on training set\n",
    "        model.fit(x_train, y_train, T=T, tol = 1)\n",
    "\n",
    "        # Test model on training set\n",
    "        scores_train = model.score(x_train, y_train)\n",
    "        print('Training set mean accuracy: {:.4f}'.format(scores_train))\n",
    "\n",
    "        # Test model on validation set\n",
    "        scores_val = model.score(x_val, y_val)\n",
    "        print('Validation set mean accuracy: {:.4f}'.format(scores_val))\n",
    "\n",
    "        # Save the model and its score\n",
    "        models.append(model)\n",
    "        scores.append(scores_val)\n",
    "\n",
    "    # Select the best performing model on the validation set\n",
    "    best_idx = np.argmax(scores)\n",
    "\n",
    "    print('Using best model trained with {} steps'.format(steps[best_idx]))\n",
    "\n",
    "    # Test model on testing set\n",
    "    scores_test = model.score(x_test, y_test)\n",
    "    print('Testing set mean accuracy: {:.4f}'.format(scores_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
